{
 "metadata": {
  "name": "",
  "signature": "sha256:960262df4021f7746ab4257556bb5b11849eeddb7a925cea5653cfa98ecca440"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function `unpunctuate` takes a string and removes all punctuation\n",
      "\n",
      "import string\n",
      "\n",
      "def unpunctuate(s):\n",
      "    y = \"\" \n",
      "    for x in s:\n",
      "        if x not in string.punctuation:\n",
      "            y = y + x\n",
      "    return y\n",
      "\n",
      "    \n",
      "unpunctuate(\"Hey there! How's it going?\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 432,
       "text": [
        "'Hey there Hows it going'"
       ]
      }
     ],
     "prompt_number": 432
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function get_bag_of_words_for_single_document takes a document or string and returns \n",
      "# it's bag of words\n",
      "import re\n",
      "from nltk import FreqDist\n",
      "\n",
      "def get_bag_of_words_for_single_document(s):\n",
      "    x = unpunctuate(s)\n",
      "    x = FreqDist(x.split())\n",
      "    return x.items()\n",
      "get_bag_of_words_for_single_document(\"John also likes likes to watch football games.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 433,
       "text": [
        "[('to', 1),\n",
        " ('football', 1),\n",
        " ('watch', 1),\n",
        " ('also', 1),\n",
        " ('games', 1),\n",
        " ('likes', 2),\n",
        " ('John', 1)]"
       ]
      }
     ],
     "prompt_number": 433
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function `get_bag_of_words` that uses the above function to achieve the following: \n",
      "# Given a list of strings, it returns the total bag of words for all of the documents.\n",
      "\n",
      "\n",
      "def get_bag_of_words(s):\n",
      "    y= {}\n",
      "    ss = \"\"\n",
      "    for f in s:\n",
      "        ss = ss + \" \" + f\n",
      "    y = get_bag_of_words_for_single_document(ss)\n",
      "    return y\n",
      "get_bag_of_words([\n",
      "    \"John likes to watch movies. Mary likes movies too.\",\n",
      "    \"John also likes to watch football games.\"\n",
      "])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 434,
       "text": [
        "[('also', 1),\n",
        " ('movies', 2),\n",
        " ('football', 1),\n",
        " ('watch', 2),\n",
        " ('to', 2),\n",
        " ('games', 1),\n",
        " ('likes', 3),\n",
        " ('John', 2),\n",
        " ('Mary', 1),\n",
        " ('too', 1)]"
       ]
      }
     ],
     "prompt_number": 434
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Given a bag of words for all of the documents in our data set \n",
      "# Function `turn_words_into_indices` take the keys in the bag of words and alphabetize them\n",
      "\n",
      "import operator\n",
      "\n",
      "def turn_words_into_indices(s):\n",
      "    y = \"\"\n",
      "    for x in s:\n",
      "        y = y + \" \" + x\n",
      "    return sorted(get_bag_of_words_for_single_document(y), key=operator.itemgetter(0))\n",
      "    \n",
      "print turn_words_into_indices([\"John likes to watch movies. Mary likes movies too.\",\n",
      "    \"John also likes to watch football games.\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('John', 2), ('Mary', 1), ('also', 1), ('football', 1), ('games', 1), ('likes', 3), ('movies', 2), ('to', 2), ('too', 1), ('watch', 2)]\n"
       ]
      }
     ],
     "prompt_number": 528
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Given a document, write a function `vectorize` that turns the document into a list \n",
      "# (also will be called a vector) the same length as the number of keys of bag of words where\n",
      "# for each index of the list will be 1 only if the word at that index in the word list is contained \n",
      "# in the document and 0 otherwise.\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "vocab = [\"also\", \"football\", \"games\", \"John\", \"likes\", \"Mary\", \"movies\", \"to\", \"too\", \"watch\"]\n",
      "test_set = [\"The sun also rises\"]\n",
      "\n",
      "def vectorize(s):\n",
      "    v = CountVectorizer(vocabulary=vocab, tokenizer=nltk.word_tokenize)\n",
      "    x = v.fit_transform(s).toarray()\n",
      "    print x\n",
      "vectorize([\"The sun also rises. Let's go to the movies\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1 0 0 0 0 0 1 1 0 0]]\n"
       ]
      }
     ],
     "prompt_number": 621
    }
   ],
   "metadata": {}
  }
 ]
}
